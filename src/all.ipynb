{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['images', 'sample_submission.csv', 'test.csv', 'train.csv']\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os, glob\n",
    "import random\n",
    "import csv\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "path = \"../dataset/train.csv\"\n",
    "imgpath = \"../dataset/images/\"\n",
    "# def read_csv(csvpath,imgpath):\n",
    "#         # self.csv_path = csvpath\n",
    "#         # self.imgpath = imgpath\n",
    "#         train = pd.read_csv(csvpath)\n",
    "#         train['image'] = train[\"Id\"].map(lambda x:f\"{imgpath}/{x:0>4}.jpg\")\n",
    "#         assert len(train[\"image\"])==len(train[\"label\"])\n",
    "#         return list(train[\"image\"]),list(train[\"label\"])\n",
    "\n",
    "# img,lael = read_csv(path,imgpath)\n",
    "dir = os.listdir(\"../dataset/\")\n",
    "print(dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "class Mydataset(Dataset):\n",
    "    def __init__(self,root,mode,resize):\n",
    "        super(Mydataset,self).__init__()\n",
    "        self.root = root\n",
    "        self.resize = resize\n",
    "        self.dirs = os.listdir(self.root)\n",
    "        if mode == \"train\":\n",
    "            self.imgpath,self.csv_path = self.root+self.dirs[0],self.root+self.dirs[-1]\n",
    "            self.ImgPathList,self.LabelPathList = self.read_csv(self.csv_path,self.imgpath)\n",
    "        if mode==\"test\":\n",
    "            self.imgpath,self.csv_path = self.root+self.dirs[0],self.root+self.dirs[-2]\n",
    "            self.ImgPathList,self.LabelPathList = self.read_csv(self.csv_path,self.imgpath)\n",
    "        \n",
    "    def read_csv(self,csvpath,imgpath):\n",
    "        self.csv_path = csvpath\n",
    "        self.imgpath = imgpath\n",
    "        train = pd.read_csv(csvpath)\n",
    "        train['image'] = train[\"Id\"].map(lambda x:f\"{imgpath}/{x:0>4}.jpg\")\n",
    "        assert len(train[\"image\"])==len(train[\"label\"])\n",
    "        return list(train[\"image\"]),list(train[\"label\"])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img,label = self.ImgPathList[index],self.LabelPathList[index]\n",
    "        img = Image.open(img).convert(\"RGB\")\n",
    "        transform = transforms.Compose([transforms.Resize((int(self.resize), int(self.resize))),\n",
    "                                     transforms.RandomRotation(15),\n",
    "                                     transforms.CenterCrop(self.resize),\n",
    "                                     transforms.ToTensor(),  # 先变成tensor类型数据，然后在进行下面的标准化\n",
    "                                     ])\n",
    "\n",
    "        image = transform(img)\n",
    "        label_dict = {\"glass\":0,\"cup\":1,\"spoon\":2,\"plate\":3,\"knife\":4,\"fork\":5}\n",
    "        label = label_dict[label]\n",
    "        label = torch.tensor(label) \n",
    "        return image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.LabelPathList)\n",
    "\n",
    "\n",
    "def create_dataloader(data_path, mode, size, batch_size,\n",
    "                    num_workers=0):  # 用一个函数加载上诉的数据，data_path、mode和size分别是以上定义的Dataset_self(）中的参数，batch_size是一次性输出多少张图像，num_worker是同时处理几张图像\n",
    "    \n",
    "    dataset = Mydataset(data_path, mode, size)\n",
    "    dataloader = DataLoader(dataset, batch_size, num_workers)  # 使用pytorch中的dataloader函数得到数据\n",
    "\n",
    "    return dataloader\n",
    "\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    data_path = \"../dataset/\"\n",
    "    dataloader = create_dataloader(data_path,mode=\"train\",size=224,batch_size=64)\n",
    "    for img,label in dataloader:\n",
    "        print(img.shape)\n",
    "        print(label.shape)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "# 先写好resnet的block块\n",
    "class Res_block(nn.Module):\n",
    "    def __init__(self, in_num, out_num, stride):\n",
    "        super(Res_block, self).__init__()\n",
    "        self.cov1 = nn.Conv2d(in_num, out_num, (3, 3), stride=stride,\n",
    "                              padding=1)  # (3,3)  padding=1 则图像大小不变，stride为几图像就缩小几倍，能极大减少参数\n",
    "        self.bn1 = nn.BatchNorm2d(out_num)\n",
    "        self.cov2 = nn.Conv2d(out_num, out_num, (3, 3), padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_num)\n",
    "\n",
    "        self.extra = nn.Sequential(\n",
    "            nn.Conv2d(in_num, out_num, (1, 1), stride=stride),\n",
    "            nn.BatchNorm2d(out_num)\n",
    "        )  # 使得输入前后的图像数据大小是一致的\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.relu(self.bn1(self.cov1(x)))\n",
    "        out = self.relu(self.bn2(self.cov2(out)))\n",
    "\n",
    "        out = self.extra(x) + out\n",
    "        return out\n",
    "\n",
    "\n",
    "class Res_net(nn.Module):\n",
    "    def __init__(self, num_class):\n",
    "        super(Res_net, self).__init__()\n",
    "        self.init = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, (3, 3)),\n",
    "            nn.BatchNorm2d(16)\n",
    "        )  # 预处理\n",
    "        self.bn1 = Res_block(16, 32, 2)\n",
    "        self.bn2 = Res_block(32, 64, 2)\n",
    "        self.bn3 = Res_block(64, 128, 2)\n",
    "        self.bn4 = Res_block(128, 256, 2)\n",
    "        self.fl = nn.Flatten()\n",
    "        self.linear1 = nn.Linear(100352, 10)\n",
    "        self.linear2 = nn.Linear(10, num_class)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.relu(self.init(x))\n",
    "        # print('inint:',out.shape)\n",
    "        out = self.bn1(out)\n",
    "        # print('bn1:', out.shape)\n",
    "        out = self.bn2(out)\n",
    "        # print('bn2:', out.shape)\n",
    "        out = self.bn3(out)\n",
    "        # print('bn3:', out.shape)\n",
    "        out = self.fl(out)\n",
    "        #print('flatten:', out.shape)\n",
    "        out = self.relu(self.linear1(out))\n",
    "        # print('linear1:', out.shape)\n",
    "        out = self.relu(self.linear2(out))\n",
    "        # print('linear2:', out.shape)\n",
    "        return out\n",
    "\n",
    "\n",
    "# 测试\n",
    "def main():\n",
    "    x = torch.randn(1, 3, 224, 224)\n",
    "    net = Res_net(6)\n",
    "    out = net(x)\n",
    "    print(out.shape)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [0/10]:  20%|█▉        | 17/87 [00:18<01:17,  1.10s/it, acc=0.0938, loss=1.81]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [54], line 58\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[39m#     # if i%10==0:\u001b[39;00m\n\u001b[0;32m     50\u001b[0m         \u001b[39m#     #     pbar.set_description(\"loss:{}\".format(loss))\u001b[39;00m\n\u001b[0;32m     51\u001b[0m         \u001b[39m#     epoch_loss+=loss.item()\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[39m# train_list.append(train_acc)\u001b[39;00m\n\u001b[0;32m     55\u001b[0m         \u001b[39m# print('train_acc', train_acc)\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m\u001b[39m==\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m---> 58\u001b[0m     train()\n",
      "Cell \u001b[1;32mIn [54], line 30\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     28\u001b[0m pbar \u001b[39m=\u001b[39m tqdm(\u001b[39menumerate\u001b[39m(dataloader),total\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(dataloader))\n\u001b[0;32m     29\u001b[0m epoch_loss \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m---> 30\u001b[0m \u001b[39mfor\u001b[39;00m i,(img,label) \u001b[39min\u001b[39;00m pbar:\n\u001b[0;32m     31\u001b[0m     out \u001b[39m=\u001b[39m net(img\u001b[39m.\u001b[39mto(device))\n\u001b[0;32m     32\u001b[0m     out \u001b[39m=\u001b[39m out\u001b[39m.\u001b[39mcpu()\n",
      "File \u001b[1;32md:\\Miniconda3\\envs\\torch\\lib\\site-packages\\tqdm\\std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1192\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[0;32m   1194\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1195\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[0;32m   1196\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[0;32m   1197\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1198\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32md:\\Miniconda3\\envs\\torch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:530\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    528\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    529\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()\n\u001b[1;32m--> 530\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    531\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    532\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    533\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    534\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32md:\\Miniconda3\\envs\\torch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:570\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    568\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    569\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 570\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    571\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    572\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data)\n",
      "File \u001b[1;32md:\\Miniconda3\\envs\\torch\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[0;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[1;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32md:\\Miniconda3\\envs\\torch\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[0;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[1;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn [49], line 24\u001b[0m, in \u001b[0;36mMydataset.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, index):\n\u001b[0;32m     23\u001b[0m     img,label \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mImgPathList[index],\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mLabelPathList[index]\n\u001b[1;32m---> 24\u001b[0m     img \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39;49mopen(img)\u001b[39m.\u001b[39;49mconvert(\u001b[39m\"\u001b[39;49m\u001b[39mRGB\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m     25\u001b[0m     transform \u001b[39m=\u001b[39m transforms\u001b[39m.\u001b[39mCompose([transforms\u001b[39m.\u001b[39mResize((\u001b[39mint\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresize), \u001b[39mint\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresize))),\n\u001b[0;32m     26\u001b[0m                                  transforms\u001b[39m.\u001b[39mRandomRotation(\u001b[39m15\u001b[39m),\n\u001b[0;32m     27\u001b[0m                                  transforms\u001b[39m.\u001b[39mCenterCrop(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresize),\n\u001b[0;32m     28\u001b[0m                                  transforms\u001b[39m.\u001b[39mToTensor(),  \u001b[39m# 先变成tensor类型数据，然后在进行下面的标准化\u001b[39;00m\n\u001b[0;32m     29\u001b[0m                                  ])\n\u001b[0;32m     31\u001b[0m     image \u001b[39m=\u001b[39m transform(img)\n",
      "File \u001b[1;32md:\\Miniconda3\\envs\\torch\\lib\\site-packages\\PIL\\Image.py:901\u001b[0m, in \u001b[0;36mImage.convert\u001b[1;34m(self, mode, matrix, dither, palette, colors)\u001b[0m\n\u001b[0;32m    856\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconvert\u001b[39m(\n\u001b[0;32m    857\u001b[0m     \u001b[39mself\u001b[39m, mode\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, matrix\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, dither\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, palette\u001b[39m=\u001b[39mPalette\u001b[39m.\u001b[39mWEB, colors\u001b[39m=\u001b[39m\u001b[39m256\u001b[39m\n\u001b[0;32m    858\u001b[0m ):\n\u001b[0;32m    859\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    860\u001b[0m \u001b[39m    Returns a converted copy of this image. For the \"P\" mode, this\u001b[39;00m\n\u001b[0;32m    861\u001b[0m \u001b[39m    method translates pixels through the palette.  If mode is\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    898\u001b[0m \u001b[39m    :returns: An :py:class:`~PIL.Image.Image` object.\u001b[39;00m\n\u001b[0;32m    899\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mload()\n\u001b[0;32m    903\u001b[0m     has_transparency \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minfo\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mtransparency\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    904\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m mode \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mP\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    905\u001b[0m         \u001b[39m# determine default mode\u001b[39;00m\n",
      "File \u001b[1;32md:\\Miniconda3\\envs\\torch\\lib\\site-packages\\PIL\\ImageFile.py:257\u001b[0m, in \u001b[0;36mImageFile.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mOSError\u001b[39;00m(\n\u001b[0;32m    252\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mimage file is truncated \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    253\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(b)\u001b[39m}\u001b[39;00m\u001b[39m bytes not processed)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    254\u001b[0m         )\n\u001b[0;32m    256\u001b[0m b \u001b[39m=\u001b[39m b \u001b[39m+\u001b[39m s\n\u001b[1;32m--> 257\u001b[0m n, err_code \u001b[39m=\u001b[39m decoder\u001b[39m.\u001b[39;49mdecode(b)\n\u001b[0;32m    258\u001b[0m \u001b[39mif\u001b[39;00m n \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    259\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torch import optim\n",
    "from tqdm import tqdm\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def evaluate(model, loader):  # 计算每次训练后的准确率\n",
    "    correct = 0\n",
    "    model.cpu()\n",
    "    total = len(loader.dataset)\n",
    "    for x, y in loader:\n",
    "        logits = model(x)\n",
    "        pred = logits.argmax(dim=1)  # 得到logits中分类值（要么是[1,0]要么是[0,1]表示分成两个类别）\n",
    "        correct += torch.eq(pred, y).sum().float().item()  # 用logits和标签label想比较得到分类正确的个数\n",
    "    return correct / total\n",
    "\n",
    "\n",
    "def train():\n",
    "    epochs=10\n",
    "    net = Res_net(6).to(device)\n",
    "    data_path = \"../dataset/\"\n",
    "    dataloader = create_dataloader(data_path,mode=\"train\",size=224,batch_size=64)\n",
    "    # test_dataloader = create_dataloader(data_path,\"test\",size=224,batch_size=64)\n",
    "    optimizer = optim.Adam(net.parameters(),lr=0.00067)\n",
    "    cirteron = nn.CrossEntropyLoss()\n",
    "    losses=[]\n",
    "    acc = []\n",
    "    for epoch in range(epochs):\n",
    "        net.train()\n",
    "        pbar = tqdm(enumerate(dataloader),total=len(dataloader))\n",
    "        epoch_loss = 0\n",
    "        for i,(img,label) in pbar:\n",
    "            out = net(img.to(device))\n",
    "            out = out.cpu()\n",
    "            loss = cirteron(out,label)\n",
    "            losses.append(loss)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            \n",
    "            \n",
    "            pre = torch.argmax(out)\n",
    "            num_correct = (pre==label).sum()\n",
    "            train_acc = float(num_correct)/float(img.shape[0])\n",
    "            acc.append(train_acc)\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            pbar.set_description(f'Epoch [{epoch}/{epochs}]')\n",
    "            pbar.set_postfix(loss=loss.item(),acc=train_acc)\n",
    "        #     # if i%10==0:\n",
    "        #     #     pbar.set_description(\"loss:{}\".format(loss))\n",
    "        #     epoch_loss+=loss.item()\n",
    "        #     print(\"Epoch_loss:{}\".format(epoch_loss/len(dataloader.dataset)))\n",
    "        # train_acc = evaluate(net, dataloader)\n",
    "        # train_list.append(train_acc)\n",
    "        # print('train_acc', train_acc)\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    train()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 60/60 [00:06<00:00,  9.16it/s]\n",
      "C:\\Users\\wang\\AppData\\Local\\Temp\\ipykernel_1540\\610718300.py:10: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for i in tqdm_notebook(range(600)):\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [56], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m \tsleep(\u001b[39m.1\u001b[39m)\n\u001b[0;32m      9\u001b[0m \u001b[39m# 专为notebook设计的进度条\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m tqdm_notebook(\u001b[39mrange\u001b[39;49m(\u001b[39m600\u001b[39;49m)):\n\u001b[0;32m     11\u001b[0m \t\u001b[39m#TODO:\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \tsleep(\u001b[39m.1\u001b[39m)\n",
      "File \u001b[1;32md:\\Miniconda3\\envs\\torch\\lib\\site-packages\\tqdm\\__init__.py:28\u001b[0m, in \u001b[0;36mtqdm_notebook\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mnotebook\u001b[39;00m \u001b[39mimport\u001b[39;00m tqdm \u001b[39mas\u001b[39;00m _tqdm_notebook\n\u001b[0;32m     25\u001b[0m warn(\u001b[39m\"\u001b[39m\u001b[39mThis function will be removed in tqdm==5.0.0\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m     26\u001b[0m      \u001b[39m\"\u001b[39m\u001b[39mPlease use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     27\u001b[0m      TqdmDeprecationWarning, stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m---> 28\u001b[0m \u001b[39mreturn\u001b[39;00m _tqdm_notebook(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32md:\\Miniconda3\\envs\\torch\\lib\\site-packages\\tqdm\\notebook.py:243\u001b[0m, in \u001b[0;36mtqdm_notebook.__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    241\u001b[0m unit_scale \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39munit_scale \u001b[39mis\u001b[39;00m \u001b[39mTrue\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39munit_scale \u001b[39mor\u001b[39;00m \u001b[39m1\u001b[39m\n\u001b[0;32m    242\u001b[0m total \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtotal \u001b[39m*\u001b[39m unit_scale \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtotal \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtotal\n\u001b[1;32m--> 243\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontainer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstatus_printer(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp, total, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdesc, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mncols)\n\u001b[0;32m    244\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontainer\u001b[39m.\u001b[39mpbar \u001b[39m=\u001b[39m proxy(\u001b[39mself\u001b[39m)\n\u001b[0;32m    245\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdisplayed \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32md:\\Miniconda3\\envs\\torch\\lib\\site-packages\\tqdm\\notebook.py:118\u001b[0m, in \u001b[0;36mtqdm_notebook.status_printer\u001b[1;34m(_, total, desc, ncols)\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[39m# Fallback to text bar if there's no total\u001b[39;00m\n\u001b[0;32m    110\u001b[0m \u001b[39m# DEPRECATED: replaced with an 'info' style bar\u001b[39;00m\n\u001b[0;32m    111\u001b[0m \u001b[39m# if not total:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    115\u001b[0m \n\u001b[0;32m    116\u001b[0m \u001b[39m# Prepare IPython progress bar\u001b[39;00m\n\u001b[0;32m    117\u001b[0m \u001b[39mif\u001b[39;00m IProgress \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:  \u001b[39m# #187 #451 #558 #872\u001b[39;00m\n\u001b[1;32m--> 118\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(WARN_NOIPYW)\n\u001b[0;32m    119\u001b[0m \u001b[39mif\u001b[39;00m total:\n\u001b[0;32m    120\u001b[0m     pbar \u001b[39m=\u001b[39m IProgress(\u001b[39mmin\u001b[39m\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, \u001b[39mmax\u001b[39m\u001b[39m=\u001b[39mtotal)\n",
      "\u001b[1;31mImportError\u001b[0m: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm,trange,tnrange,tqdm_notebook\n",
    "from time import sleep\n",
    "\n",
    "# 普通进度条\n",
    "for i in trange(60):\n",
    "\t#TODO:\n",
    "\tsleep(.1)\n",
    "\n",
    "# 专为notebook设计的进度条\n",
    "for i in tqdm_notebook(range(600)):\n",
    "\t#TODO:\n",
    "\tsleep(.1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d30c415e52c387ef28d770f1c5e3eb8aa24d6884df82fa2808f92248cea45e8e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
